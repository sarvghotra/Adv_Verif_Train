{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_data_path = \"/lustre/fsw/portfolios/llmservice/users/sghotra/data/gen/pv_methd/preproc_gsm8k_pos/full\"\n",
    "\n",
    "# read the datasets (huggingface)\n",
    "# group by \"ids\"\n",
    "# from neg dataset, remove responses w/ label=1\n",
    "# merge the datasets: 50% of responses from each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre/fsw/portfolios/llmservice/users/sghotra/installs/miniforge3/envs/adv_verif/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# read the datasets (huggingface)\n",
    "from datasets import load_from_disk\n",
    "pos_data = load_from_disk(pos_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text', 'question', 'answer', 'id', 'target', 'response', 'label', 'gen_id'])\n"
     ]
    }
   ],
   "source": [
    "print(pos_data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by \"ids\"\n",
    "pos_data_grp = {}\n",
    "for i in range(len(pos_data)):\n",
    "    id = pos_data[i][\"id\"]\n",
    "    \n",
    "    if id in pos_data_grp:\n",
    "        pos_data_grp[id].append(pos_data[i])\n",
    "    else:\n",
    "        pos_data_grp[id] = [pos_data[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of incomplete datapoints: 2607\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(6730)\n",
    "\n",
    "# merge the pos and neg datasets: 50% of responses from each dataset.\n",
    "\n",
    "incomplete_dpoints = 0\n",
    "\n",
    "merged_data = []\n",
    "all_ids = set(pos_data_grp.keys())\n",
    "for id in all_ids:\n",
    "    pos_dp_h = []\n",
    "    neg_dp_h = []\n",
    "\n",
    "    if id in pos_data_grp:\n",
    "        pos_dp = pos_data_grp[id]\n",
    "        random.shuffle(pos_dp)\n",
    "        pos_dp_h = pos_dp\n",
    "\n",
    "        for dp in pos_dp_h:\n",
    "            dp[\"policy\"] = \"pos\"\n",
    "    \n",
    "\n",
    "    # if len(neg_dp_h) < 8:\n",
    "    #     neg_dp_h = neg_dp.shuffle()[:8]\n",
    "    #     if len(neg_dp_h) < 8:\n",
    "    #         pos_dp_h = pos_dp.shuffle()[:8]\n",
    "    \n",
    "    # if len(pos_dp_h) < 8:\n",
    "    #     pos_dp_h = pos_dp.shuffle()[:8]\n",
    "\n",
    "    dp = pos_dp_h + neg_dp_h\n",
    "    merged_data.extend(dp)\n",
    "\n",
    "    if len(dp) < 16:\n",
    "        incomplete_dpoints += 1\n",
    "    \n",
    "print(f\"Number of incomplete datapoints: {incomplete_dpoints}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data:  115361\n",
      "dict_keys(['text', 'question', 'answer', 'id', 'target', 'response', 'label', 'gen_id', 'policy'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Merged data: \", len(merged_data))\n",
    "print(merged_data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2221365/2441908778.py:2: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  val_ids = random.sample(all_ids, 500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:  107727\n",
      "Val data:  7634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 107727/107727 [00:00<00:00, 876723.82 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 7634/7634 [00:00<00:00, 649584.45 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# random select 500 ids for val set\n",
    "val_ids = random.sample(all_ids, 500)\n",
    "\n",
    "train_data = []\n",
    "val_data = []\n",
    "\n",
    "for dp in merged_data:\n",
    "    if dp[\"id\"] in val_ids:\n",
    "        val_data.append(dp)\n",
    "    else:\n",
    "        train_data.append(dp)\n",
    "\n",
    "print(\"Train data: \", len(train_data))\n",
    "print(\"Val data: \", len(val_data))\n",
    "\n",
    "\n",
    "# save the datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "output_dir = \"/lustre/fsw/portfolios/llmservice/users/sghotra/data/gen/pv_methd/preproc_gsm8k_pos/full/splits\"\n",
    "\n",
    "train_data_dict = {key: [d[key] for d in train_data] for key in train_data[0]}\n",
    "train_dataset = Dataset.from_dict(train_data_dict)\n",
    "\n",
    "val_data_dict = {key: [d[key] for d in val_data] for key in val_data[0]}\n",
    "val_dataset = Dataset.from_dict(val_data_dict)\n",
    "\n",
    "from datasets import DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "        'train': train_dataset,\n",
    "        'eval': val_dataset\n",
    "    })\n",
    "\n",
    "\n",
    "dataset_dict.save_to_disk(output_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_verif",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
